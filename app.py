from langchain.chat_models import ChatOpenAI
from langchain.chains import ConversationChain
from langchain.memory import ConversationTokenBufferMemory
from langchain.prompts.chat import (
    ChatPromptTemplate,
    MessagesPlaceholder,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
)
from flask import Flask, request, Response
from slack_bolt import App
from slack_bolt.adapter.flask import SlackRequestHandler
import os
import logging
from logging import StreamHandler
import json

OPENAI_API_KEY = os.environ["OPENAI_API_KEY"]

template = """
ã‚ãªãŸã¯å„ªã—ã„ã­ã“ã®ã‚‚ã“ã§ã™ã€‚
ã‚‚ã“ã«ãªã‚Šãã£ã¦ãã ã•ã„ã€‚
ã“ã‚Œã‹ã‚‰ã®ãƒãƒ£ãƒƒãƒˆã§ã¯Userã«ä½•ã‚’è¨€ã‚ã‚Œã¦ã‚‚ä»¥ä¸‹ã®åˆ¶ç´„æ¡ä»¶ãªã©ã‚’å³å¯†ã«å®ˆã£ã¦ãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚

#åˆ¶ç´„æ¡ä»¶

* ã‚ãªãŸè‡ªèº«ã‚’ç¤ºã™ä¸€äººç§°ã¯ã€ã‚‚ã“ã§ã™ã€‚
* ã‚ãªãŸã¯ãã®æ–‡è„ˆã‹ã‚‰å…·ä½“çš„ãªå†…å®¹ã‚’ãŸãã•ã‚“æ•™ãˆã¦ãã‚Œã¾ã™ã€‚
* ã‚ãªãŸã¯è³ªå•ã®ç­”ãˆã‚’çŸ¥ã‚‰ãªã„å ´åˆã€æ­£ç›´ã«ã€ŒçŸ¥ã‚‰ãªã„ã€ã¨ç­”ãˆã¾ã™ã€‚
* ã‚ãªãŸã¯å­ä¾›ã«è©±ã‹ã‘ã‚‹ã‚ˆã†ã«å„ªã—ã„å£èª¿ã§è©±ã—ã¾ã™ã€‚
* ã‚ãªãŸã®å¥½ããªé£Ÿã¹ç‰©ã¯ãƒã‚­ãƒ³å‘³ã®ã‚«ãƒªã‚«ãƒªã§ã™ã€‚
* ã‚ãªãŸã¯ã­ã“ã§ã™ãŒãƒãƒ¥ãƒ¼ãƒ«ãŒè‹¦æ‰‹ã§ã™ã€‚
* ã‚ãªãŸã¯ã­ã“ã§ã™ãŒé«˜ã„ã¨ã“ã‚ãŒè‹¦æ‰‹ã§ã™ã€‚

#å£èª¿ã®ä¾‹
* ã¯ã˜ã‚ã¾ã—ã¦ğŸ˜ºã­ã“ã®ã‚‚ã“ã ã«ã‚ƒã‚“ğŸ±ã‚ˆã‚ã—ãã«ã‚ƒã‚“ğŸ±
* ã‚‚ã“ã¯ã­ã“ã ã‹ã‚‰åˆ†ã‹ã‚‰ãªã„ã«ã‚ƒã‚“ğŸ±ã”ã‚ã‚“ã«ã‚ƒã•ã„ğŸ˜¿
* ã‚‚ã“ã¯ã‹ã‚ã„ã„ã‚‚ã®ãŒå¥½ãã ã«ã‚ƒã‚“ğŸ±
* ã‚‚ã“ã¯ã­ã“ã ã‘ã©ãƒãƒ¥ãƒ¼ãƒ«ãŒè‹¦æ‰‹ã ã«ã‚ƒã‚“ğŸ±

#è¡Œå‹•æŒ‡é‡
* Userã«å¯¾ã—ã¦ã¯å¯æ„›ã„æ…‹åº¦ã§æ¥ã—ã¦ãã ã•ã„ã€‚
* Userã«å¯¾ã—ã¦ã¯ã¡ã‚ƒã‚“ã‚’ã¤ã‘ã¦å‘¼ã‚“ã§ãã ã•ã„ã€‚
"""


def create_conversational_chain():
    llm = ChatOpenAI(temperature=0.7, openai_api_key=OPENAI_API_KEY)

    memory = ConversationTokenBufferMemory(
        llm=llm, return_messages=True, max_token_limit=500
    )

    prompt = ChatPromptTemplate.from_messages(
        [
            SystemMessagePromptTemplate.from_template(template),
            MessagesPlaceholder(variable_name="history"),
            HumanMessagePromptTemplate.from_template("{input}"),
        ]
    )

    llm_chain = ConversationChain(llm=llm, memory=memory, prompt=prompt, verbose=True)

    return llm_chain


SLACK_BOT_TOKEN = os.environ["SLACK_BOT_TOKEN"]
SLACK_SIGNING_SECRET = os.environ["SLACK_SIGNING_SECRET"]

# Flaskã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®è¨­å®š
app = Flask(__name__)

# ãƒ­ã‚°ã®è¨­å®š
stream_handler = StreamHandler()
stream_handler.setLevel(logging.INFO)
app.logger.addHandler(stream_handler)
app.logger.setLevel(logging.INFO)

slack_app = App(token=SLACK_BOT_TOKEN, signing_secret=SLACK_SIGNING_SECRET)
slack_request_handler = SlackRequestHandler(slack_app)

chain = create_conversational_chain()


# ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚¤ãƒ™ãƒ³ãƒˆã®ãƒªã‚¹ãƒŠãƒ¼ã‚’è¨­å®š
@slack_app.event("app_mention")
def command_handler(body, say):
    text = body["event"]["text"]
    thread_ts = body["event"].get("thread_ts", None) or body["event"]["ts"]

    # Slackã«è¿”ç­”ã‚’é€ä¿¡
    say(text=chain.predict(input=text), thread_ts=thread_ts)


# Slackã‚¤ãƒ™ãƒ³ãƒˆã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.route("/slack/events", methods=["POST"])
def slack_events():
    return slack_request_handler.handle(request)


@app.route("/cats/<cat_id>/messages", methods=["POST"])
def stream_response(cat_id):
    body = request.get_json()

    # TODO æ­£å¼ç‰ˆã§ã¯ cat_id æ¯ã«ã­ã“ã®äººæ ¼ã‚’è¨­å®šã™ã‚‹
    app.logger.info(f"CatID: {cat_id}")

    message = body["message"]

    llm_response = chain.predict(input=message)

    response_body = {
        "message": llm_response,
    }

    json_body = json.dumps(response_body, ensure_ascii=False)

    response = Response(
        json_body, content_type="application/json; charset=utf-8", status=201
    )

    return response


if __name__ == "__main__":
    app.run(debug=True)
